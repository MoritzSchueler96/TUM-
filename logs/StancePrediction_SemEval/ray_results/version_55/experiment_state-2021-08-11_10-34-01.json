{
  "checkpoints": [
    "{\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"e1646_00004\",\n  \"config\": {\n    \"dataset_path\": \"../../data/raw/SemEval/\",\n    \"learning_rate\": 0.0002823434428431044,\n    \"batch_size\": 64,\n    \"epochs\": 5,\n    \"num_trials\": 5\n  },\n  \"local_dir\": \"/home/user/Documents/Github/Uni/Master/TUM_Praktikum_NLP_Explainability/understanding-opinions-on-social-media/logs/StancePrediction_SemEval/ray_results/version_55\",\n  \"evaluated_params\": {\n    \"learning_rate\": 0.0002823434428431044,\n    \"batch_size\": 64\n  },\n  \"experiment_tag\": \"4_batch_size=64,learning_rate=0.00028234\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"resources\": {\n    \"cpu\": 1,\n    \"gpu\": 0,\n    \"memory\": 0,\n    \"object_store_memory\": 0,\n    \"extra_cpu\": 0,\n    \"extra_gpu\": 0,\n    \"extra_memory\": 0,\n    \"extra_object_store_memory\": 0,\n    \"custom_resources\": {},\n    \"extra_custom_resources\": {}\n  },\n  \"placement_group_factory\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b2000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944b018c03475055944b008c066d656d6f7279944b008c136f626a6563745f73746f72655f6d656d6f7279944b0075618c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\"\n  },\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"last_result\": {\n    \"loss\": 2.3180506229400635,\n    \"mean_F1\": 0.46237337589263916,\n    \"time_this_iter_s\": 393.8929636478424,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"experiment_id\": \"dd55243aaa5d4a4e8ef0c1c21eb23916\",\n    \"date\": \"2021-08-11_10-40-39\",\n    \"timestamp\": 1628671239,\n    \"time_total_s\": 393.8929636478424,\n    \"pid\": 171264,\n    \"hostname\": \"TP-X1-C7\",\n    \"node_ip\": \"192.168.178.75\",\n    \"config\": {\n      \"dataset_path\": \"../../data/raw/SemEval/\",\n      \"learning_rate\": 0.0002823434428431044,\n      \"batch_size\": 64,\n      \"epochs\": 5,\n      \"num_trials\": 5,\n      \"vocab_size\": 30522,\n      \"target_encoding\": {\n        \"0\": \"Atheism\",\n        \"1\": \"Climate Change is a Real Concern\",\n        \"2\": \"Feminist Movement\",\n        \"3\": \"Hillary Clinton\",\n        \"4\": \"Legalization of Abortion\"\n      },\n      \"stance_encoding\": {\n        \"0\": \"AGAINST\",\n        \"1\": \"FAVOR\",\n        \"2\": \"NONE\",\n        \"3\": \"UNKNOWN\"\n      }\n    },\n    \"time_since_restore\": 393.8929636478424,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"trial_id\": \"e1646_00004\",\n    \"experiment_tag\": \"4_batch_size=64,learning_rate=0.00028234\"\n  },\n  \"last_update_time\": 1628671239.3082805,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 2.3180506229400635,\n      \"min\": 2.3180506229400635,\n      \"avg\": 2.3180506229400635,\n      \"last\": 2.3180506229400635,\n      \"last-5-avg\": 2.3180506229400635,\n      \"last-10-avg\": 2.3180506229400635\n    },\n    \"mean_F1\": {\n      \"max\": 0.46237337589263916,\n      \"min\": 0.46237337589263916,\n      \"avg\": 0.46237337589263916,\n      \"last\": 0.46237337589263916,\n      \"last-5-avg\": 0.46237337589263916,\n      \"last-10-avg\": 0.46237337589263916\n    },\n    \"time_this_iter_s\": {\n      \"max\": 393.8929636478424,\n      \"min\": 393.8929636478424,\n      \"avg\": 393.8929636478424,\n      \"last\": 393.8929636478424,\n      \"last-5-avg\": 393.8929636478424,\n      \"last-10-avg\": 393.8929636478424\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"timestamp\": {\n      \"max\": 1628671239,\n      \"min\": 1628671239,\n      \"avg\": 1628671239,\n      \"last\": 1628671239,\n      \"last-5-avg\": 1628671239,\n      \"last-10-avg\": 1628671239\n    },\n    \"time_total_s\": {\n      \"max\": 393.8929636478424,\n      \"min\": 393.8929636478424,\n      \"avg\": 393.8929636478424,\n      \"last\": 393.8929636478424,\n      \"last-5-avg\": 393.8929636478424,\n      \"last-10-avg\": 393.8929636478424\n    },\n    \"pid\": {\n      \"max\": 171264,\n      \"min\": 171264,\n      \"avg\": 171264,\n      \"last\": 171264,\n      \"last-5-avg\": 171264,\n      \"last-10-avg\": 171264\n    },\n    \"time_since_restore\": {\n      \"max\": 393.8929636478424,\n      \"min\": 393.8929636478424,\n      \"avg\": 393.8929636478424,\n      \"last\": 393.8929636478424,\n      \"last-5-avg\": 393.8929636478424,\n      \"last-10-avg\": 393.8929636478424\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"config/learning_rate\": {\n      \"max\": 0.0002823434428431044,\n      \"min\": 0.0002823434428431044,\n      \"avg\": 0.0002823434428431044,\n      \"last\": 0.0002823434428431044,\n      \"last-5-avg\": 0.0002823434428431044,\n      \"last-10-avg\": 0.0002823434428431044\n    },\n    \"config/batch_size\": {\n      \"max\": 64,\n      \"min\": 64,\n      \"avg\": 64,\n      \"last\": 64,\n      \"last-5-avg\": 64,\n      \"last-10-avg\": 64\n    },\n    \"config/epochs\": {\n      \"max\": 5,\n      \"min\": 5,\n      \"avg\": 5,\n      \"last\": 5,\n      \"last-5-avg\": 5,\n      \"last-10-avg\": 5\n    },\n    \"config/num_trials\": {\n      \"max\": 5,\n      \"min\": 5,\n      \"avg\": 5,\n      \"last\": 5,\n      \"last-5-avg\": 5,\n      \"last-10-avg\": 5\n    },\n    \"config/vocab_size\": {\n      \"max\": 30522,\n      \"min\": 30522,\n      \"avg\": 30522,\n      \"last\": 30522,\n      \"last-5-avg\": 30522,\n      \"last-10-avg\": 30522\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740028b5e20000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740028b5e20000000612e\"\n      }\n    },\n    \"mean_F1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fdd978680000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fdd978680000000612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740789e4994400000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740789e4994400000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"timestamp\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944a078d1361612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944a078d1361612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740789e4994400000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740789e4994400000612e\"\n      }\n    },\n    \"pid\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944a009d0200612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944a009d0200612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740789e4994400000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740789e4994400000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"config/learning_rate\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473f3280efda6eab54612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473f3280efda6eab54612e\"\n      }\n    },\n    \"config/batch_size\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b40612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b40612e\"\n      }\n    },\n    \"config/epochs\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b05612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b05612e\"\n      }\n    },\n    \"config/num_trials\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b05612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b05612e\"\n      }\n    },\n    \"config/vocab_size\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944d3a77612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944d3a77612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1628670842.4525936,\n  \"logdir\": \"/home/user/Documents/Github/Uni/Master/TUM_Praktikum_NLP_Explainability/understanding-opinions-on-social-media/logs/StancePrediction_SemEval/ray_results/version_55/train_tune_e1646_00004_4_batch_size=64,learning_rate=0.00028234_2021-08-11_10-34-02\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059566010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d9475628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9475628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"e1646_00002\",\n  \"config\": {\n    \"dataset_path\": \"../../data/raw/SemEval/\",\n    \"learning_rate\": 0.00231387319446209,\n    \"batch_size\": 16,\n    \"epochs\": 5,\n    \"num_trials\": 5\n  },\n  \"local_dir\": \"/home/user/Documents/Github/Uni/Master/TUM_Praktikum_NLP_Explainability/understanding-opinions-on-social-media/logs/StancePrediction_SemEval/ray_results/version_55\",\n  \"evaluated_params\": {\n    \"learning_rate\": 0.00231387319446209,\n    \"batch_size\": 16\n  },\n  \"experiment_tag\": \"2_batch_size=16,learning_rate=0.0023139\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"resources\": {\n    \"cpu\": 1,\n    \"gpu\": 0,\n    \"memory\": 0,\n    \"object_store_memory\": 0,\n    \"extra_cpu\": 0,\n    \"extra_gpu\": 0,\n    \"extra_memory\": 0,\n    \"extra_object_store_memory\": 0,\n    \"custom_resources\": {},\n    \"extra_custom_resources\": {}\n  },\n  \"placement_group_factory\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b2000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944b018c03475055944b008c066d656d6f7279944b008c136f626a6563745f73746f72655f6d656d6f7279944b0075618c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\"\n  },\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"last_result\": {\n    \"loss\": 1.9759886264801025,\n    \"mean_F1\": 0.534453809261322,\n    \"time_this_iter_s\": 336.11444449424744,\n    \"done\": false,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"experiment_id\": \"c0c83b2a490c4efc84de3ddb3141174a\",\n    \"date\": \"2021-08-11_10-39-41\",\n    \"timestamp\": 1628671181,\n    \"time_total_s\": 336.11444449424744,\n    \"pid\": 171262,\n    \"hostname\": \"TP-X1-C7\",\n    \"node_ip\": \"192.168.178.75\",\n    \"config\": {\n      \"dataset_path\": \"../../data/raw/SemEval/\",\n      \"learning_rate\": 0.00231387319446209,\n      \"batch_size\": 16,\n      \"epochs\": 5,\n      \"num_trials\": 5,\n      \"vocab_size\": 30522,\n      \"target_encoding\": {\n        \"0\": \"Atheism\",\n        \"1\": \"Climate Change is a Real Concern\",\n        \"2\": \"Feminist Movement\",\n        \"3\": \"Hillary Clinton\",\n        \"4\": \"Legalization of Abortion\"\n      },\n      \"stance_encoding\": {\n        \"0\": \"AGAINST\",\n        \"1\": \"FAVOR\",\n        \"2\": \"NONE\",\n        \"3\": \"UNKNOWN\"\n      }\n    },\n    \"time_since_restore\": 336.11444449424744,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"trial_id\": \"e1646_00002\",\n    \"experiment_tag\": \"2_batch_size=16,learning_rate=0.0023139\"\n  },\n  \"last_update_time\": 1628671181.446619,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 1.9759886264801025,\n      \"min\": 1.9759886264801025,\n      \"avg\": 1.9759886264801025,\n      \"last\": 1.9759886264801025,\n      \"last-5-avg\": 1.9759886264801025,\n      \"last-10-avg\": 1.9759886264801025\n    },\n    \"mean_F1\": {\n      \"max\": 0.534453809261322,\n      \"min\": 0.534453809261322,\n      \"avg\": 0.534453809261322,\n      \"last\": 0.534453809261322,\n      \"last-5-avg\": 0.534453809261322,\n      \"last-10-avg\": 0.534453809261322\n    },\n    \"time_this_iter_s\": {\n      \"max\": 336.11444449424744,\n      \"min\": 336.11444449424744,\n      \"avg\": 336.11444449424744,\n      \"last\": 336.11444449424744,\n      \"last-5-avg\": 336.11444449424744,\n      \"last-10-avg\": 336.11444449424744\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"timestamp\": {\n      \"max\": 1628671181,\n      \"min\": 1628671181,\n      \"avg\": 1628671181,\n      \"last\": 1628671181,\n      \"last-5-avg\": 1628671181,\n      \"last-10-avg\": 1628671181\n    },\n    \"time_total_s\": {\n      \"max\": 336.11444449424744,\n      \"min\": 336.11444449424744,\n      \"avg\": 336.11444449424744,\n      \"last\": 336.11444449424744,\n      \"last-5-avg\": 336.11444449424744,\n      \"last-10-avg\": 336.11444449424744\n    },\n    \"pid\": {\n      \"max\": 171262,\n      \"min\": 171262,\n      \"avg\": 171262,\n      \"last\": 171262,\n      \"last-5-avg\": 171262,\n      \"last-10-avg\": 171262\n    },\n    \"time_since_restore\": {\n      \"max\": 336.11444449424744,\n      \"min\": 336.11444449424744,\n      \"avg\": 336.11444449424744,\n      \"last\": 336.11444449424744,\n      \"last-5-avg\": 336.11444449424744,\n      \"last-10-avg\": 336.11444449424744\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"config/learning_rate\": {\n      \"max\": 0.00231387319446209,\n      \"min\": 0.00231387319446209,\n      \"avg\": 0.00231387319446209,\n      \"last\": 0.00231387319446209,\n      \"last-5-avg\": 0.00231387319446209,\n      \"last-10-avg\": 0.00231387319446209\n    },\n    \"config/batch_size\": {\n      \"max\": 16,\n      \"min\": 16,\n      \"avg\": 16,\n      \"last\": 16,\n      \"last-5-avg\": 16,\n      \"last-10-avg\": 16\n    },\n    \"config/epochs\": {\n      \"max\": 5,\n      \"min\": 5,\n      \"avg\": 5,\n      \"last\": 5,\n      \"last-5-avg\": 5,\n      \"last-10-avg\": 5\n    },\n    \"config/num_trials\": {\n      \"max\": 5,\n      \"min\": 5,\n      \"avg\": 5,\n      \"last\": 5,\n      \"last-5-avg\": 5,\n      \"last-10-avg\": 5\n    },\n    \"config/vocab_size\": {\n      \"max\": 30522,\n      \"min\": 30522,\n      \"avg\": 30522,\n      \"last\": 30522,\n      \"last-5-avg\": 30522,\n      \"last-10-avg\": 30522\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fff9da640000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fff9da640000000612e\"\n      }\n    },\n    \"mean_F1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fe11a3ee0000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fe11a3ee0000000612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447407501d4c3c00000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447407501d4c3c00000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"timestamp\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944acd8c1361612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944acd8c1361612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447407501d4c3c00000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447407501d4c3c00000612e\"\n      }\n    },\n    \"pid\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944afe9c0200612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944afe9c0200612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447407501d4c3c00000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447407501d4c3c00000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"config/learning_rate\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473f62f48b36505418612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473f62f48b36505418612e\"\n      }\n    },\n    \"config/batch_size\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b10612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b10612e\"\n      }\n    },\n    \"config/epochs\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b05612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b05612e\"\n      }\n    },\n    \"config/num_trials\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b05612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b05612e\"\n      }\n    },\n    \"config/vocab_size\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944d3a77612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944d3a77612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"RUNNING\",\n  \"start_time\": 1628670842.3657568,\n  \"logdir\": \"/home/user/Documents/Github/Uni/Master/TUM_Praktikum_NLP_Explainability/understanding-opinions-on-social-media/logs/StancePrediction_SemEval/ray_results/version_55/train_tune_e1646_00002_2_batch_size=16,learning_rate=0.0023139_2021-08-11_10-34-02\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059566010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d9475628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9475628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"e1646_00003\",\n  \"config\": {\n    \"dataset_path\": \"../../data/raw/SemEval/\",\n    \"learning_rate\": 0.0019864216286494506,\n    \"batch_size\": 32,\n    \"epochs\": 5,\n    \"num_trials\": 5\n  },\n  \"local_dir\": \"/home/user/Documents/Github/Uni/Master/TUM_Praktikum_NLP_Explainability/understanding-opinions-on-social-media/logs/StancePrediction_SemEval/ray_results/version_55\",\n  \"evaluated_params\": {\n    \"learning_rate\": 0.0019864216286494506,\n    \"batch_size\": 32\n  },\n  \"experiment_tag\": \"3_batch_size=32,learning_rate=0.0019864\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"resources\": {\n    \"cpu\": 1,\n    \"gpu\": 0,\n    \"memory\": 0,\n    \"object_store_memory\": 0,\n    \"extra_cpu\": 0,\n    \"extra_gpu\": 0,\n    \"extra_memory\": 0,\n    \"extra_object_store_memory\": 0,\n    \"custom_resources\": {},\n    \"extra_custom_resources\": {}\n  },\n  \"placement_group_factory\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b2000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944b018c03475055944b008c066d656d6f7279944b008c136f626a6563745f73746f72655f6d656d6f7279944b0075618c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\"\n  },\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"last_result\": {},\n  \"last_update_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"export_formats\": [],\n  \"status\": \"RUNNING\",\n  \"start_time\": 1628670842.398885,\n  \"logdir\": \"/home/user/Documents/Github/Uni/Master/TUM_Praktikum_NLP_Explainability/understanding-opinions-on-social-media/logs/StancePrediction_SemEval/ray_results/version_55/train_tune_e1646_00003_3_batch_size=32,learning_rate=0.0019864_2021-08-11_10-34-02\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059566010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d9475628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9475628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"e1646_00000\",\n  \"config\": {\n    \"dataset_path\": \"../../data/raw/SemEval/\",\n    \"learning_rate\": 0.0010175931055835738,\n    \"batch_size\": 64,\n    \"epochs\": 5,\n    \"num_trials\": 5\n  },\n  \"local_dir\": \"/home/user/Documents/Github/Uni/Master/TUM_Praktikum_NLP_Explainability/understanding-opinions-on-social-media/logs/StancePrediction_SemEval/ray_results/version_55\",\n  \"evaluated_params\": {\n    \"learning_rate\": 0.0010175931055835738,\n    \"batch_size\": 64\n  },\n  \"experiment_tag\": \"0_batch_size=64,learning_rate=0.0010176\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"resources\": {\n    \"cpu\": 1,\n    \"gpu\": 0,\n    \"memory\": 0,\n    \"object_store_memory\": 0,\n    \"extra_cpu\": 0,\n    \"extra_gpu\": 0,\n    \"extra_memory\": 0,\n    \"extra_object_store_memory\": 0,\n    \"custom_resources\": {},\n    \"extra_custom_resources\": {}\n  },\n  \"placement_group_factory\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b2000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944b018c03475055944b008c066d656d6f7279944b008c136f626a6563745f73746f72655f6d656d6f7279944b0075618c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\"\n  },\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"last_result\": {\n    \"loss\": 1.9977314472198486,\n    \"mean_F1\": 0.5159189701080322,\n    \"time_this_iter_s\": 374.396523475647,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"experiment_id\": \"e3aa06fb62e14c31a86c4a4060ed91a7\",\n    \"date\": \"2021-08-11_10-40-19\",\n    \"timestamp\": 1628671219,\n    \"time_total_s\": 374.396523475647,\n    \"pid\": 171257,\n    \"hostname\": \"TP-X1-C7\",\n    \"node_ip\": \"192.168.178.75\",\n    \"config\": {\n      \"dataset_path\": \"../../data/raw/SemEval/\",\n      \"learning_rate\": 0.0010175931055835738,\n      \"batch_size\": 64,\n      \"epochs\": 5,\n      \"num_trials\": 5,\n      \"vocab_size\": 30522,\n      \"target_encoding\": {\n        \"0\": \"Atheism\",\n        \"1\": \"Climate Change is a Real Concern\",\n        \"2\": \"Feminist Movement\",\n        \"3\": \"Hillary Clinton\",\n        \"4\": \"Legalization of Abortion\"\n      },\n      \"stance_encoding\": {\n        \"0\": \"AGAINST\",\n        \"1\": \"FAVOR\",\n        \"2\": \"NONE\",\n        \"3\": \"UNKNOWN\"\n      }\n    },\n    \"time_since_restore\": 374.396523475647,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"trial_id\": \"e1646_00000\",\n    \"experiment_tag\": \"0_batch_size=64,learning_rate=0.0010176\"\n  },\n  \"last_update_time\": 1628671219.7388132,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 1.9977314472198486,\n      \"min\": 1.9977314472198486,\n      \"avg\": 1.9977314472198486,\n      \"last\": 1.9977314472198486,\n      \"last-5-avg\": 1.9977314472198486,\n      \"last-10-avg\": 1.9977314472198486\n    },\n    \"mean_F1\": {\n      \"max\": 0.5159189701080322,\n      \"min\": 0.5159189701080322,\n      \"avg\": 0.5159189701080322,\n      \"last\": 0.5159189701080322,\n      \"last-5-avg\": 0.5159189701080322,\n      \"last-10-avg\": 0.5159189701080322\n    },\n    \"time_this_iter_s\": {\n      \"max\": 374.396523475647,\n      \"min\": 374.396523475647,\n      \"avg\": 374.396523475647,\n      \"last\": 374.396523475647,\n      \"last-5-avg\": 374.396523475647,\n      \"last-10-avg\": 374.396523475647\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"timestamp\": {\n      \"max\": 1628671219,\n      \"min\": 1628671219,\n      \"avg\": 1628671219,\n      \"last\": 1628671219,\n      \"last-5-avg\": 1628671219,\n      \"last-10-avg\": 1628671219\n    },\n    \"time_total_s\": {\n      \"max\": 374.396523475647,\n      \"min\": 374.396523475647,\n      \"avg\": 374.396523475647,\n      \"last\": 374.396523475647,\n      \"last-5-avg\": 374.396523475647,\n      \"last-10-avg\": 374.396523475647\n    },\n    \"pid\": {\n      \"max\": 171257,\n      \"min\": 171257,\n      \"avg\": 171257,\n      \"last\": 171257,\n      \"last-5-avg\": 171257,\n      \"last-10-avg\": 171257\n    },\n    \"time_since_restore\": {\n      \"max\": 374.396523475647,\n      \"min\": 374.396523475647,\n      \"avg\": 374.396523475647,\n      \"last\": 374.396523475647,\n      \"last-5-avg\": 374.396523475647,\n      \"last-10-avg\": 374.396523475647\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"config/learning_rate\": {\n      \"max\": 0.0010175931055835738,\n      \"min\": 0.0010175931055835738,\n      \"avg\": 0.0010175931055835738,\n      \"last\": 0.0010175931055835738,\n      \"last-5-avg\": 0.0010175931055835738,\n      \"last-10-avg\": 0.0010175931055835738\n    },\n    \"config/batch_size\": {\n      \"max\": 64,\n      \"min\": 64,\n      \"avg\": 64,\n      \"last\": 64,\n      \"last-5-avg\": 64,\n      \"last-10-avg\": 64\n    },\n    \"config/epochs\": {\n      \"max\": 5,\n      \"min\": 5,\n      \"avg\": 5,\n      \"last\": 5,\n      \"last-5-avg\": 5,\n      \"last-10-avg\": 5\n    },\n    \"config/num_trials\": {\n      \"max\": 5,\n      \"min\": 5,\n      \"avg\": 5,\n      \"last\": 5,\n      \"last-5-avg\": 5,\n      \"last-10-avg\": 5\n    },\n    \"config/vocab_size\": {\n      \"max\": 30522,\n      \"min\": 30522,\n      \"avg\": 30522,\n      \"last\": 30522,\n      \"last-5-avg\": 30522,\n      \"last-10-avg\": 30522\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473ffff6b540000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473ffff6b540000000612e\"\n      }\n    },\n    \"mean_F1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fe0826880000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fe0826880000000612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474077665829000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474077665829000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"timestamp\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944af38c1361612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944af38c1361612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474077665829000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474077665829000000612e\"\n      }\n    },\n    \"pid\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944af99c0200612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944af99c0200612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474077665829000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474077665829000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"config/learning_rate\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473f50ac1846fbc3e0612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473f50ac1846fbc3e0612e\"\n      }\n    },\n    \"config/batch_size\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b40612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b40612e\"\n      }\n    },\n    \"config/epochs\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b05612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b05612e\"\n      }\n    },\n    \"config/num_trials\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b05612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b05612e\"\n      }\n    },\n    \"config/vocab_size\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944d3a77612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944d3a77612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1628670842.3116279,\n  \"logdir\": \"/home/user/Documents/Github/Uni/Master/TUM_Praktikum_NLP_Explainability/understanding-opinions-on-social-media/logs/StancePrediction_SemEval/ray_results/version_55/train_tune_e1646_00000_0_batch_size=64,learning_rate=0.0010176_2021-08-11_10-34-02\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059566010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d9475628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9475628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"e1646_00001\",\n  \"config\": {\n    \"dataset_path\": \"../../data/raw/SemEval/\",\n    \"learning_rate\": 0.001547961646339978,\n    \"batch_size\": 64,\n    \"epochs\": 5,\n    \"num_trials\": 5\n  },\n  \"local_dir\": \"/home/user/Documents/Github/Uni/Master/TUM_Praktikum_NLP_Explainability/understanding-opinions-on-social-media/logs/StancePrediction_SemEval/ray_results/version_55\",\n  \"evaluated_params\": {\n    \"learning_rate\": 0.001547961646339978,\n    \"batch_size\": 64\n  },\n  \"experiment_tag\": \"1_batch_size=64,learning_rate=0.001548\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"resources\": {\n    \"cpu\": 1,\n    \"gpu\": 0,\n    \"memory\": 0,\n    \"object_store_memory\": 0,\n    \"extra_cpu\": 0,\n    \"extra_gpu\": 0,\n    \"extra_memory\": 0,\n    \"extra_object_store_memory\": 0,\n    \"custom_resources\": {},\n    \"extra_custom_resources\": {}\n  },\n  \"placement_group_factory\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b2000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944b018c03475055944b008c066d656d6f7279944b008c136f626a6563745f73746f72655f6d656d6f7279944b0075618c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\"\n  },\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"last_result\": {},\n  \"last_update_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"export_formats\": [],\n  \"status\": \"RUNNING\",\n  \"start_time\": 1628670842.3380322,\n  \"logdir\": \"/home/user/Documents/Github/Uni/Master/TUM_Praktikum_NLP_Explainability/understanding-opinions-on-social-media/logs/StancePrediction_SemEval/ray_results/version_55/train_tune_e1646_00001_1_batch_size=64,learning_rate=0.001548_2021-08-11_10-34-02\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059566010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d9475628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9475628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}"
  ],
  "runner_data": {
    "_max_pending_trials": 16,
    "_metric": "loss",
    "_total_time": 3621.298266172409,
    "_iteration": 31,
    "_has_errored": false,
    "_fail_fast": false,
    "_server_port": null,
    "_cached_trial_decisions": {},
    "_queued_trial_decisions": {},
    "_updated_queue": true,
    "_should_stop_experiment": false,
    "_local_checkpoint_dir": "/home/user/Documents/Github/Uni/Master/TUM_Praktikum_NLP_Explainability/understanding-opinions-on-social-media/logs/StancePrediction_SemEval/ray_results/version_55",
    "_remote_checkpoint_dir": null,
    "_stopper": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "80059527000000000000008c107261792e74756e652e73746f70706572948c0b4e6f6f7053746f707065729493942981942e"
    },
    "_resumed": false,
    "_start_time": 1628670841.980792,
    "_last_checkpoint_time": -Infinity,
    "_session_str": "2021-08-11_10-34-01",
    "checkpoint_file": "/home/user/Documents/Github/Uni/Master/TUM_Praktikum_NLP_Explainability/understanding-opinions-on-social-media/logs/StancePrediction_SemEval/ray_results/version_55/experiment_state-2021-08-11_10-34-01.json",
    "_checkpoint_period": "auto",
    "launch_web_server": false
  },
  "stats": {
    "start_time": 1628670841.980792,
    "timestamp": 1628671756.5225763
  }
}